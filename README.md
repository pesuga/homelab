# ğŸ  Homelab: Agentic Workflow Platform

> **Mission**: Build an open-source, self-hosted agentic workflow platform with local LLM inference, accessible both locally and remotely.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Active%20Development-green)]()
[![Built with Claude](https://img.shields.io/badge/Built%20with-Claude-purple)]()

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Documentation](#documentation)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This homelab project creates a production-ready, self-hosted platform for building and running agentic workflows with local LLM inference. Everything runs on your own hardware, ensuring complete data sovereignty and privacy.

### Key Components

- **ğŸ§  LLM Inference**: Local model hosting with GPU acceleration (AMD RX 7800 XT)
- **ğŸ”„ Workflow Automation**: N8n for visual workflow building
- **ğŸŒŠ LLM Flow Builder**: Flowise for low-code AI app development
- **ğŸ¤– Agent Framework**: AgentStack for advanced agent orchestration
- **â˜¸ï¸ Orchestration**: Kubernetes for service management
- **ğŸ”’ Secure Access**: Tailscale for zero-trust networking
- **ğŸ“Š Observability**: Full metrics, logging, and alerting stack

---

## ğŸ—ï¸ Architecture

### Hardware Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Network Layer                             â”‚
â”‚  GL-MT2500 Firewall + Tailscale Exit Node                   â”‚
â”‚  â€¢ Secure gateway  â€¢ VPN  â€¢ Traffic routing                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Compute Node    â”‚                  â”‚   Service Node     â”‚
â”‚  (WSL/Ubuntu)    â”‚                  â”‚   (Linux Server)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ LLM Inference  â”‚                  â”‚ â€¢ K8s Cluster      â”‚
â”‚ â€¢ Ollama/vLLM    â”‚                  â”‚ â€¢ N8n              â”‚
â”‚ â€¢ LiteLLM Router â”‚                  â”‚ â€¢ AgentStack       â”‚
â”‚ â€¢ GPU (RX 7800XT)â”‚                  â”‚ â€¢ PostgreSQL       â”‚
â”‚ â€¢ Development    â”‚                  â”‚ â€¢ Redis            â”‚
â”‚                  â”‚                  â”‚ â€¢ Observability    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  i5-12400F, 32GB                       i7, 16GB RAM
```

### Software Stack

```
Application Layer
â”œâ”€â”€ N8n (Workflow Automation)
â”œâ”€â”€ Flowise (LLM Flow Builder)
â”œâ”€â”€ AgentStack (Agent Framework)
â””â”€â”€ Custom Agents

Inference Layer
â”œâ”€â”€ Ollama (Model Management)
â”œâ”€â”€ LiteLLM (Router & Load Balancer)
â””â”€â”€ Local LLM Models

Orchestration Layer
â”œâ”€â”€ Kubernetes (K3s)
â”œâ”€â”€ Docker
â””â”€â”€ Helm Charts

Data Layer
â”œâ”€â”€ PostgreSQL (Persistent Storage)
â”œâ”€â”€ Redis (Caching & Queues)
â”œâ”€â”€ Qdrant (Vector Database)
â””â”€â”€ Object Storage (Future)

Observability Layer
â”œâ”€â”€ Prometheus (Metrics)
â”œâ”€â”€ Grafana (Dashboards)
â”œâ”€â”€ Loki (Log Aggregation)
â”œâ”€â”€ Promtail (Log Collection)
â””â”€â”€ AlertManager (Alerts - Future)

GitOps Layer
â””â”€â”€ Flux CD (Automated Deployments - Ready for Bootstrap)

Network Layer
â””â”€â”€ Tailscale (Zero-Trust VPN)
```

---

## âœ¨ Features

### Core Capabilities

- âœ… **Local LLM Inference** with GPU acceleration (In Progress)
- âœ… **Smart Model Routing** with automatic failover (Planned)
- âœ… **Visual Workflow Builder** (N8n)
- âœ… **LLM Flow Builder** (Flowise)
- âœ… **Vector Database** for RAG (Qdrant)
- âœ… **Memory Layer** for LLM context (Mem0)
- âœ… **Agent Framework** for complex automations (Future)
- âœ… **Kubernetes Orchestration** for scalability
- âœ… **Zero-Trust Networking** via Tailscale
- âœ… **Full Observability** with Prometheus, Grafana & Loki
- âœ… **GitOps Deployments** with Flux CD (Ready for Bootstrap)
- âœ… **Mobile Access** from anywhere securely

### Design Principles

1. **ğŸ  Local-First**: All compute and data stays in your network
2. **ğŸ”“ Open Source**: Built on and contributing to OSS
3. **ğŸ§© Modular**: Services are independent and composable
4. **ğŸ‘ï¸ Observable**: Everything is logged and monitored
5. **ğŸ¤– Automated**: Manual work is automated away
6. **ğŸ“š Documented**: Comprehensive documentation
7. **ğŸ—‚ï¸ Version Controlled**: All code and config in Git
8. **ğŸ¤ Claude-Assisted**: Developed with AI pair programming

---

## ğŸ“¦ Prerequisites

### Hardware Requirements

#### Compute Node (Required)
- CPU: 6+ cores (Intel i5-12400F or equivalent) âœ… *Currently: i5-12400F*
- RAM: 32GB minimum âœ… *Currently: 32GB DDR4*
- GPU: AMD RX 7800 XT (or equivalent with 8GB+ VRAM) âœ… *Currently: RX 7800 XT 16GB*
- Storage: 500GB+ NVMe SSD âœ… *Currently: 937GB available*
- OS: Ubuntu 25.10 (Native installation) âœ… *Currently: Ubuntu 25.10 Questing Quetzal*

#### Service Node (Required)
- CPU: 4+ cores (Intel i7 or equivalent) âœ… *Currently: i7-4510U*
- RAM: 8GB minimum (16GB recommended) âœ… *Currently: 8GB*
- Storage: 100GB+ SSD âœ… *Currently: 98GB*
- OS: Linux (Ubuntu 22.04+ LTS) âœ… *Currently: Ubuntu 24.04.3 LTS*

#### Network Hardware (Required)
- Router with OpenWRT support (GL-MT2500 or equivalent)
- Gigabit Ethernet connectivity
- Internet connection with static IP or DDNS

### Software Requirements

- **Docker** 24.0+
- **Kubernetes** (K3s 1.27+)
- **Git** 2.40+
- **Node.js** 18+ LTS
- **Python** 3.11+
- **Claude Code** (latest)

### Accounts Needed

- GitHub account
- Tailscale account (free tier works)
- Notion account (optional, for documentation)

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/homelab.git
cd homelab
git checkout revised-version
```

### 2. Run Setup Script

```bash
./scripts/setup.sh
```

This will:
- Verify prerequisites
- Set up environment variables
- Configure Tailscale
- Deploy base infrastructure
- Run health checks

### 3. Deploy Services

```bash
# Deploy to Compute Node (LLM Inference)
cd infrastructure/compute-node
./deploy.sh

# Deploy to Service Node (K8s cluster)
cd infrastructure/service-node
./deploy.sh
```

### 4. Access Services

Once deployed, services are available at:

**Local Network Access:**
- **N8n**: http://192.168.8.185:30678 (admin/admin123)
- **Grafana**: http://192.168.8.185:30300 (admin/admin123)
- **Prometheus**: http://192.168.8.185:30090

**Via Tailscale (remote access):**
- **N8n**: http://100.81.76.55:30678
- **Grafana**: http://100.81.76.55:30300
- **Prometheus**: http://100.81.76.55:30090

---

## ğŸ“ Project Structure

```
homelab/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ LICENSE                        # MIT License
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ .env.example                  # Environment template
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # System architecture
â”‚   â”œâ”€â”€ DEPLOYMENT.md             # Deployment guide
â”‚   â”œâ”€â”€ DEVELOPMENT.md            # Development guide
â”‚   â”œâ”€â”€ NETWORKING.md             # Network setup
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md        # Common issues
â”‚   â””â”€â”€ API.md                    # API documentation
â”‚
â”œâ”€â”€ infrastructure/               # Infrastructure as Code
â”‚   â”œâ”€â”€ kubernetes/               # K8s manifests
â”‚   â”‚   â”œâ”€â”€ base/                 # Base configs
â”‚   â”‚   â”œâ”€â”€ overlays/             # Environment overlays
â”‚   â”‚   â””â”€â”€ apps/                 # Application deployments
â”‚   â”œâ”€â”€ terraform/                # Terraform configs
â”‚   â”‚   â”œâ”€â”€ network/              # Network setup
â”‚   â”‚   â””â”€â”€ compute/              # Compute resources
â”‚   â”œâ”€â”€ compute-node/             # Compute node setup
â”‚   â”‚   â”œâ”€â”€ ollama/               # Ollama configs
â”‚   â”‚   â”œâ”€â”€ litellm/              # LiteLLM configs
â”‚   â”‚   â””â”€â”€ scripts/              # Setup scripts
â”‚   â””â”€â”€ service-node/             # Service node setup
â”‚       â”œâ”€â”€ k8s-setup/            # K8s installation
â”‚       â””â”€â”€ base-services/        # Core services
â”‚
â”œâ”€â”€ services/                     # Service configurations
â”‚   â”œâ”€â”€ n8n-workflows/            # N8n workflow exports
â”‚   â”‚   â”œâ”€â”€ templates/            # Workflow templates
â”‚   â”‚   â””â”€â”€ custom/               # Custom workflows
â”‚   â”œâ”€â”€ agentstack-config/        # AgentStack configs
â”‚   â”‚   â”œâ”€â”€ agents/               # Agent definitions
â”‚   â”‚   â””â”€â”€ tools/                # Agent tools
â”‚   â””â”€â”€ llm-router/               # LiteLLM configuration
â”‚       â”œâ”€â”€ models.yaml           # Model definitions
â”‚       â””â”€â”€ routes.yaml           # Routing rules
â”‚
â”œâ”€â”€ agents/                       # Custom agent implementations
â”‚   â”œâ”€â”€ examples/                 # Example agents
â”‚   â”œâ”€â”€ templates/                # Agent templates
â”‚   â””â”€â”€ production/               # Production agents
â”‚
â”œâ”€â”€ observability/                # Monitoring configs
â”‚   â”œâ”€â”€ grafana/                  # Dashboards
â”‚   â”œâ”€â”€ prometheus/               # Metrics configs
â”‚   â”œâ”€â”€ loki/                     # Log configs
â”‚   â””â”€â”€ alertmanager/             # Alert rules
â”‚
â”œâ”€â”€ scripts/                      # Automation scripts
â”‚   â”œâ”€â”€ setup.sh                  # Initial setup
â”‚   â”œâ”€â”€ deploy.sh                 # Deployment
â”‚   â”œâ”€â”€ backup.sh                 # Backup routines
â”‚   â”œâ”€â”€ restore.sh                # Restore routines
â”‚   â””â”€â”€ health-check.sh           # Health checks
â”‚
â””â”€â”€ tests/                        # Test suites
    â”œâ”€â”€ unit/                     # Unit tests
    â”œâ”€â”€ integration/              # Integration tests
    â””â”€â”€ e2e/                      # End-to-end tests
```

---

## ğŸ“š Documentation

Comprehensive documentation is available in the `/docs` directory:

### Core Documentation
- **[Architecture](docs/ARCHITECTURE.md)**: System design and components
- **[Deployment Guide](docs/DEPLOYMENT.md)**: Step-by-step deployment
- **[Development Guide](docs/DEVELOPMENT.md)**: Contributing and development
- **[Networking](docs/NETWORKING.md)**: Network configuration
- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Common issues and solutions

### Service-Specific Guides
- **[LLM Setup](docs/LLM-SETUP.md)**: AMD GPU, ROCm, Ollama, and LiteLLM deployment
- **[Qdrant Setup](docs/QDRANT-SETUP.md)**: Vector database deployment and integration
- **[GitOps Setup](docs/GITOPS-SETUP.md)**: Flux CD installation and multi-repo management
- **[Grafana Dashboards](docs/GRAFANA-DASHBOARDS.md)**: Dashboard creation and configuration

### Planning & Analysis
- **[Implementation Plan](docs/IMPLEMENTATION-PLAN.md)**: GitOps, Qdrant, and Grafana roadmap
- **[Metrics Analysis](docs/METRICS-ANALYSIS.md)**: Prometheus metrics catalog
- **[Session State](docs/SESSION-STATE.md)**: Current development progress

---

## ğŸ—“ï¸ Roadmap

### Sprint 0: Foundation (Weeks 1-2) âœ… COMPLETED
- [x] Repository setup
- [x] Documentation structure
- [x] Tailscale installation and configuration
- [x] K8s cluster setup (K3s v1.33.5)
- [x] Base infrastructure deployed

**Completed Infrastructure:**
- Docker v28.5.1 installed
- K3s cluster running on asuna (192.168.8.185)
- Tailscale VPN configured (100.81.76.55)
- Subnet routing enabled (192.168.86.0/24)

### Sprint 1: Core Services (Weeks 3-4) âœ… COMPLETED
- [x] PostgreSQL deployment (postgres:16-alpine, 10Gi storage)
- [x] Redis deployment (redis:7-alpine)
- [x] N8n deployment (workflow automation, 5Gi storage)
- [x] Service networking configured
- [x] Basic authentication setup

**Deployed Services:**
- PostgreSQL 16.10: ClusterIP on port 5432 (10Gi storage, User: homelab/DB: homelab)
- Redis 7.4.6: ClusterIP on port 6379 (ephemeral storage, AOF enabled)
- N8n: NodePort 30678 (accessible locally and via Tailscale, 5Gi storage)

### Sprint 2: Observability (Weeks 5-6) âœ… COMPLETED
- [x] Prometheus setup (10Gi storage)
- [x] Grafana dashboards (5Gi storage)
- [x] Kubernetes metrics collection
- [x] Service discovery configured
- [x] Basic monitoring stack operational

**Monitoring Stack:**
- Prometheus: NodePort 30090
- Grafana: NodePort 30300
- RBAC configured for cluster metrics

### Sprint 3: LLM Infrastructure (Weeks 7-8) ğŸ”„ IN PROGRESS (RESTARTED)
- [x] Fresh Ubuntu 25.10 installation on compute node
- [x] GPU detection verified (AMD RX 7800 XT)
- [ ] ROCm installation (AMD GPU drivers)
- [ ] Ollama installation with GPU support
- [ ] LiteLLM deployment
- [ ] Model management and testing
- [ ] Performance benchmarking
- [ ] Tailscale setup on compute node
- [ ] Integration with service node

### Sprint 4: Advanced Services (Weeks 9-10) âœ… COMPLETED
- [x] PostgreSQL deployment and documentation
- [x] Redis deployment and documentation
- [x] Database services integrated with homelab dashboard
- [x] Qdrant vector database deployed to K3s cluster
- [x] Mem0 AI memory layer deployed and integrated
- [x] GitOps with Flux CD structure created (ready for bootstrap)
- [x] Grafana dashboards created (Homelab Infrastructure - dual node)
- [x] Prometheus metrics analyzed and integrated
- [x] Log aggregation with Loki deployed (service + compute nodes)
- [x] Promtail log collection configured (K8s DaemonSet + systemd)
- [x] Flowise authentication resolved and database reset
- [x] Open WebUI account reset
- [ ] Bootstrap Flux CD for GitOps (requires GitHub token)
- [ ] Integrate LLM services with N8n workflows (depends on Sprint 3)
- [ ] AgentStack setup (optional)
- [ ] Alert rules and runbooks (future)

### Sprint 5: Networking & Security (Weeks 11-12)
- [x] Tailscale subnets (completed)
- [ ] Exit node setup
- [ ] Mobile access optimization
- [ ] Enhanced authentication
- [ ] Access procedures documentation

### Sprint 6: Agent Workflows (Weeks 13-14)
- [ ] First N8n workflow
- [ ] LLM integration with N8n
- [ ] AgentStack agent development
- [ ] Agent templates
- [ ] Pattern documentation

### Sprint 7: CI/CD & Automation (Weeks 15-16)
- [ ] GitHub Actions setup
- [ ] Automated testing
- [ ] Deployment pipelines
- [ ] Backup automation
- [ ] Disaster recovery procedures

---

## ğŸ¤ Contributing

Contributions are welcome! This is a personal homelab project, but if you find it useful and want to contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Workflow

This project uses Claude Code for AI-assisted development:

```bash
# Start Claude Code in the project directory
cd homelab
claude

# Claude has access to:
# - Project files (via filesystem MCP)
# - GitHub (via GitHub MCP)
# - Documentation (via Notion MCP)
```

---

## ğŸ“Š Project Status

**Current Phase**: Sprint 3 & 4 - LLM Infrastructure + Advanced Services (Parallel)
**Progress**: 50% (2 sprints completed, 2 in progress)
**Next Milestone**: ROCm + Ollama + LiteLLM deployment, Qdrant deployment, Grafana dashboards
**Timeline**: 16 weeks total to full platform

### Current Deployment

**Compute Node (pesubuntu - localhost):**
- âœ… Ubuntu 25.10 native installation
- âœ… GPU detected (AMD RX 7800 XT Navi 32)
- âœ… GitHub configured and repository cloned
- â³ ROCm installation pending
- â³ Ollama + LiteLLM pending
- â³ Tailscale pending

**Service Node (asuna - 192.168.8.185):**
- âœ… K3s v1.33.5 cluster (1 node)
- âœ… Docker v28.5.1
- âœ… Tailscale (100.81.76.55)
- âœ… PostgreSQL + Redis
- âœ… N8n Workflow Automation
- âœ… Flowise LLM Flow Builder
- âœ… Open WebUI
- âœ… Prometheus + Grafana
- â³ Qdrant Vector Database (ready to deploy)
- ğŸ“‹ Flux CD GitOps (planned)
- ğŸ“‹ Grafana Dashboards (planned)

**Network:**
- âœ… Local network: 192.168.8.0/24
- âœ… Tailscale mesh network active on service node
- âœ… Subnet routing enabled for 192.168.86.0/24

### Success Metrics

- **Availability**: 100% uptime (service node operational)
- **Development**: Claude-assisted deployment < 1 hour
- **Resources**: CPU < 30%, Memory < 50% (current usage)
- **Performance Targets**: LLM inference < 2s (pending), availability > 99%

---

## ğŸ”’ Security

- All data stays local (no cloud dependencies)
- Zero-trust networking via Tailscale
- Encrypted at rest and in transit
- Regular security updates
- Audit logging enabled

See [SECURITY.md](SECURITY.md) for security policies.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Claude** by Anthropic - AI pair programming
- **N8n** - Workflow automation
- **Tailscale** - Zero-trust networking
- **Ollama** - Local LLM hosting
- All the open source projects that make this possible

---

## ğŸ“ Support

- **Documentation**: [/docs](docs/)
- **Issues**: [GitHub Issues](https://github.com/yourusername/homelab/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/homelab/discussions)

---

**Built with â¤ï¸ using Claude, running locally on your hardware.**
