# ğŸ  Homelab: Agentic Workflow Platform

> **Mission**: Build an open-source, self-hosted agentic workflow platform with local LLM inference, accessible both locally and remotely.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Active%20Development-green)]()
[![Built with Claude](https://img.shields.io/badge/Built%20with-Claude-purple)]()

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Documentation](#documentation)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This homelab project creates a production-ready, self-hosted platform for building and running agentic workflows with local LLM inference. Everything runs on your own hardware, ensuring complete data sovereignty and privacy.

### Key Components

- **ğŸ§  LLM Inference**: Local model hosting with GPU acceleration (AMD RX 7800 XT)
- **ğŸ”„ Workflow Automation**: N8n for visual workflow building
- **ğŸ¤– Agent Framework**: AgentStack for advanced agent orchestration
- **â˜¸ï¸ Orchestration**: Kubernetes for service management
- **ğŸ”’ Secure Access**: Tailscale for zero-trust networking
- **ğŸ“Š Observability**: Full metrics, logging, and alerting stack

---

## ğŸ—ï¸ Architecture

### Hardware Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Network Layer                             â”‚
â”‚  GL-MT2500 Firewall + Tailscale Exit Node                   â”‚
â”‚  â€¢ Secure gateway  â€¢ VPN  â€¢ Traffic routing                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Compute Node    â”‚                  â”‚   Service Node     â”‚
â”‚  (WSL/Ubuntu)    â”‚                  â”‚   (Linux Server)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ LLM Inference  â”‚                  â”‚ â€¢ K8s Cluster      â”‚
â”‚ â€¢ Ollama/vLLM    â”‚                  â”‚ â€¢ N8n              â”‚
â”‚ â€¢ LiteLLM Router â”‚                  â”‚ â€¢ AgentStack       â”‚
â”‚ â€¢ GPU (RX 7800XT)â”‚                  â”‚ â€¢ PostgreSQL       â”‚
â”‚ â€¢ Development    â”‚                  â”‚ â€¢ Redis            â”‚
â”‚                  â”‚                  â”‚ â€¢ Observability    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  i5-12400F, 32GB                       i7, 16GB RAM
```

### Software Stack

```
Application Layer
â”œâ”€â”€ N8n (Workflow Automation)
â”œâ”€â”€ AgentStack (Agent Framework)
â””â”€â”€ Custom Agents

Inference Layer
â”œâ”€â”€ Ollama (Model Management)
â”œâ”€â”€ LiteLLM (Router & Load Balancer)
â””â”€â”€ Local LLM Models

Orchestration Layer
â”œâ”€â”€ Kubernetes (K3s)
â”œâ”€â”€ Docker
â””â”€â”€ Helm Charts

Data Layer
â”œâ”€â”€ PostgreSQL (Persistent Storage)
â”œâ”€â”€ Redis (Caching & Queues)
â””â”€â”€ Object Storage

Observability Layer
â”œâ”€â”€ Prometheus (Metrics)
â”œâ”€â”€ Grafana (Dashboards)
â”œâ”€â”€ Loki (Logs)
â””â”€â”€ AlertManager (Alerts)

Network Layer
â””â”€â”€ Tailscale (Zero-Trust VPN)
```

---

## âœ¨ Features

### Core Capabilities

- âœ… **Local LLM Inference** with GPU acceleration
- âœ… **Smart Model Routing** with automatic failover
- âœ… **Visual Workflow Builder** (N8n)
- âœ… **Agent Framework** for complex automations
- âœ… **Kubernetes Orchestration** for scalability
- âœ… **Zero-Trust Networking** via Tailscale
- âœ… **Full Observability** with metrics, logs, and traces
- âœ… **CI/CD Pipeline** for automated deployments
- âœ… **Mobile Access** from anywhere securely

### Design Principles

1. **ğŸ  Local-First**: All compute and data stays in your network
2. **ğŸ”“ Open Source**: Built on and contributing to OSS
3. **ğŸ§© Modular**: Services are independent and composable
4. **ğŸ‘ï¸ Observable**: Everything is logged and monitored
5. **ğŸ¤– Automated**: Manual work is automated away
6. **ğŸ“š Documented**: Comprehensive documentation
7. **ğŸ—‚ï¸ Version Controlled**: All code and config in Git
8. **ğŸ¤ Claude-Assisted**: Developed with AI pair programming

---

## ğŸ“¦ Prerequisites

### Hardware Requirements

#### Compute Node (Required)
- CPU: 6+ cores (Intel i5-12400F or equivalent)
- RAM: 32GB minimum
- GPU: AMD RX 7800 XT (or equivalent with 8GB+ VRAM)
- Storage: 500GB+ NVMe SSD
- OS: Windows with WSL2 (Ubuntu) or Linux

#### Service Node (Required)
- CPU: 4+ cores (Intel i7 or equivalent)
- RAM: 16GB minimum
- Storage: 256GB+ SSD
- OS: Linux (Ubuntu 22.04 LTS recommended)

#### Network Hardware (Required)
- Router with OpenWRT support (GL-MT2500 or equivalent)
- Gigabit Ethernet connectivity
- Internet connection with static IP or DDNS

### Software Requirements

- **Docker** 24.0+
- **Kubernetes** (K3s 1.27+)
- **Git** 2.40+
- **Node.js** 18+ LTS
- **Python** 3.11+
- **Claude Code** (latest)

### Accounts Needed

- GitHub account
- Tailscale account (free tier works)
- Notion account (optional, for documentation)

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/homelab.git
cd homelab
git checkout revised-version
```

### 2. Run Setup Script

```bash
./scripts/setup.sh
```

This will:
- Verify prerequisites
- Set up environment variables
- Configure Tailscale
- Deploy base infrastructure
- Run health checks

### 3. Deploy Services

```bash
# Deploy to Compute Node (LLM Inference)
cd infrastructure/compute-node
./deploy.sh

# Deploy to Service Node (K8s cluster)
cd infrastructure/service-node
./deploy.sh
```

### 4. Access Services

Once deployed, services are available at:

- **N8n**: http://n8n.homelab.local:5678
- **Grafana**: http://grafana.homelab.local:3000
- **LiteLLM**: http://llm-router.homelab.local:8000

Via Tailscale (remote access):
- All services accessible via Tailscale DNS

---

## ğŸ“ Project Structure

```
homelab/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ LICENSE                        # MIT License
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ .env.example                  # Environment template
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # System architecture
â”‚   â”œâ”€â”€ DEPLOYMENT.md             # Deployment guide
â”‚   â”œâ”€â”€ DEVELOPMENT.md            # Development guide
â”‚   â”œâ”€â”€ NETWORKING.md             # Network setup
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md        # Common issues
â”‚   â””â”€â”€ API.md                    # API documentation
â”‚
â”œâ”€â”€ infrastructure/               # Infrastructure as Code
â”‚   â”œâ”€â”€ kubernetes/               # K8s manifests
â”‚   â”‚   â”œâ”€â”€ base/                 # Base configs
â”‚   â”‚   â”œâ”€â”€ overlays/             # Environment overlays
â”‚   â”‚   â””â”€â”€ apps/                 # Application deployments
â”‚   â”œâ”€â”€ terraform/                # Terraform configs
â”‚   â”‚   â”œâ”€â”€ network/              # Network setup
â”‚   â”‚   â””â”€â”€ compute/              # Compute resources
â”‚   â”œâ”€â”€ compute-node/             # Compute node setup
â”‚   â”‚   â”œâ”€â”€ ollama/               # Ollama configs
â”‚   â”‚   â”œâ”€â”€ litellm/              # LiteLLM configs
â”‚   â”‚   â””â”€â”€ scripts/              # Setup scripts
â”‚   â””â”€â”€ service-node/             # Service node setup
â”‚       â”œâ”€â”€ k8s-setup/            # K8s installation
â”‚       â””â”€â”€ base-services/        # Core services
â”‚
â”œâ”€â”€ services/                     # Service configurations
â”‚   â”œâ”€â”€ n8n-workflows/            # N8n workflow exports
â”‚   â”‚   â”œâ”€â”€ templates/            # Workflow templates
â”‚   â”‚   â””â”€â”€ custom/               # Custom workflows
â”‚   â”œâ”€â”€ agentstack-config/        # AgentStack configs
â”‚   â”‚   â”œâ”€â”€ agents/               # Agent definitions
â”‚   â”‚   â””â”€â”€ tools/                # Agent tools
â”‚   â””â”€â”€ llm-router/               # LiteLLM configuration
â”‚       â”œâ”€â”€ models.yaml           # Model definitions
â”‚       â””â”€â”€ routes.yaml           # Routing rules
â”‚
â”œâ”€â”€ agents/                       # Custom agent implementations
â”‚   â”œâ”€â”€ examples/                 # Example agents
â”‚   â”œâ”€â”€ templates/                # Agent templates
â”‚   â””â”€â”€ production/               # Production agents
â”‚
â”œâ”€â”€ observability/                # Monitoring configs
â”‚   â”œâ”€â”€ grafana/                  # Dashboards
â”‚   â”œâ”€â”€ prometheus/               # Metrics configs
â”‚   â”œâ”€â”€ loki/                     # Log configs
â”‚   â””â”€â”€ alertmanager/             # Alert rules
â”‚
â”œâ”€â”€ scripts/                      # Automation scripts
â”‚   â”œâ”€â”€ setup.sh                  # Initial setup
â”‚   â”œâ”€â”€ deploy.sh                 # Deployment
â”‚   â”œâ”€â”€ backup.sh                 # Backup routines
â”‚   â”œâ”€â”€ restore.sh                # Restore routines
â”‚   â””â”€â”€ health-check.sh           # Health checks
â”‚
â””â”€â”€ tests/                        # Test suites
    â”œâ”€â”€ unit/                     # Unit tests
    â”œâ”€â”€ integration/              # Integration tests
    â””â”€â”€ e2e/                      # End-to-end tests
```

---

## ğŸ“š Documentation

Comprehensive documentation is available in the `/docs` directory:

- **[Architecture](docs/ARCHITECTURE.md)**: System design and components
- **[Deployment Guide](docs/DEPLOYMENT.md)**: Step-by-step deployment
- **[Development Guide](docs/DEVELOPMENT.md)**: Contributing and development
- **[Networking](docs/NETWORKING.md)**: Network configuration
- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Common issues and solutions
- **[API Documentation](docs/API.md)**: API endpoints and usage

---

## ğŸ—“ï¸ Roadmap

### Sprint 0: Foundation (Weeks 1-2) âœ…
- [x] Repository setup
- [x] Documentation structure
- [ ] Tailscale installation
- [ ] K8s cluster setup
- [ ] Base infrastructure

### Sprint 1: LLM Infrastructure (Weeks 3-4)
- [ ] Ollama installation
- [ ] LiteLLM deployment
- [ ] Model management
- [ ] GPU configuration
- [ ] Health monitoring

### Sprint 2: Core Services (Weeks 5-6)
- [ ] N8n deployment
- [ ] AgentStack setup
- [ ] PostgreSQL cluster
- [ ] Redis deployment
- [ ] Service mesh

### Sprint 3: Observability (Weeks 7-8)
- [ ] Prometheus setup
- [ ] Grafana dashboards
- [ ] Loki logging
- [ ] Alert rules
- [ ] Runbooks

### Sprint 4: Networking (Weeks 9-10)
- [ ] Tailscale subnets
- [ ] Exit node setup
- [ ] Mobile access
- [ ] Authentication
- [ ] Access procedures

### Sprint 5: Agent Workflows (Weeks 11-12)
- [ ] First N8n workflow
- [ ] LLM integration
- [ ] AgentStack agent
- [ ] Agent templates
- [ ] Pattern documentation

### Sprint 6: CI/CD (Weeks 13-14)
- [ ] GitHub Actions
- [ ] Automated testing
- [ ] Deployment pipelines
- [ ] Backup automation
- [ ] Disaster recovery

---

## ğŸ¤ Contributing

Contributions are welcome! This is a personal homelab project, but if you find it useful and want to contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Workflow

This project uses Claude Code for AI-assisted development:

```bash
# Start Claude Code in the project directory
cd homelab
claude

# Claude has access to:
# - Project files (via filesystem MCP)
# - GitHub (via GitHub MCP)
# - Documentation (via Notion MCP)
```

---

## ğŸ“Š Project Status

**Current Phase**: Sprint 0 - Foundation  
**Progress**: 20%  
**Next Milestone**: K8s cluster deployment  
**Timeline**: 12-14 weeks to full platform

### Success Metrics

- **Performance**: LLM inference < 2s, availability > 99%
- **Development**: Idea to deployment < 1 day
- **Resources**: GPU 60-80%, CPU < 70%, Memory < 75%

---

## ğŸ”’ Security

- All data stays local (no cloud dependencies)
- Zero-trust networking via Tailscale
- Encrypted at rest and in transit
- Regular security updates
- Audit logging enabled

See [SECURITY.md](SECURITY.md) for security policies.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Claude** by Anthropic - AI pair programming
- **N8n** - Workflow automation
- **Tailscale** - Zero-trust networking
- **Ollama** - Local LLM hosting
- All the open source projects that make this possible

---

## ğŸ“ Support

- **Documentation**: [/docs](docs/)
- **Issues**: [GitHub Issues](https://github.com/yourusername/homelab/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/homelab/discussions)

---

**Built with â¤ï¸ using Claude, running locally on your hardware.**
