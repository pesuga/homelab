# =============================================================================
# Monitorium Configuration File
# =============================================================================
# This file controls all aspects of the Monitorium TUI dashboard
# Location: ~/.monitorium/config.yaml
#
# To use this configuration:
# 1. Copy this file to ~/.monitorium/config.yaml
# 2. Modify the values according to your environment
# 3. Run monitorium - it will automatically load the configuration
# =============================================================================

# General application settings
general:
  # How often to refresh metrics (in seconds)
  update_interval_secs: 5

  # Number of data points to keep in history (for graphs)
  history_retention: 60

  # Connection timeout for external services (in seconds)
  connection_timeout_secs: 10

  # Start in fullscreen mode
  fullscreen: false

  # Theme: "default", "dark", "light"
  theme: "default"

# Prometheus configuration for metrics collection
prometheus:
  # Prometheus server URL
  url: "http://100.81.76.55:30090"

  # Connection timeout (in seconds)
  timeout_secs: 10

  # How often to query Prometheus (in seconds)
  query_interval_secs: 5

  # Custom Prometheus queries for node metrics
  node_queries:
    # CPU usage percentage - average across all cores
    cpu_usage: "100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)"

    # Memory usage percentage
    memory_usage: "((1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100)"

    # GPU usage percentage (if GPU metrics are available)
    # Uncomment and modify if you have GPU metrics
    # gpu_usage: "100 - (avg by (instance) (irate(nvidia_gpu_utilization_gpu{}[5m])))"

    # Network receive rate (MB/s)
    network_rx: "irate(node_network_receive_bytes_total[5m]) / 1024 / 1024"

    # Network transmit rate (MB/s)
    network_tx: "irate(node_network_transmit_bytes_total[5m]) / 1024 / 1024"

    # Disk usage percentage for root filesystem
    disk_usage: "((1 - (node_filesystem_avail_bytes{mountpoint=\"/\"} / node_filesystem_size_bytes{mountpoint=\"/\"})) * 100)"

    # Temperature in Celsius (if available)
    temperature: "node_hwmon_temp_celsius"

  # Custom Prometheus queries for service metrics
  service_queries:
    # Service up status
    service_status: "up"

    # Service CPU usage percentage
    cpu_usage: "rate(container_cpu_usage_seconds_total[5m]) * 100"

    # Service memory usage percentage
    memory_usage: "container_memory_usage_bytes / container_spec_memory_limit_bytes * 100"

    # Requests per second
    requests_per_sec: "rate(container_http_requests_total[5m])"

    # Response time in milliseconds (95th percentile)
    response_time: "histogram_quantile(0.95, rate(container_http_request_duration_seconds_bucket[5m])) * 1000"

    # Error rate percentage
    error_rate: "rate(container_http_requests_total{status=~\"5..\"}[5m]) / rate(container_http_requests_total[5m]) * 100"

  # Authentication (optional)
  # auth:
  #   username: "your-username"
  #   password: "your-password"
  #   bearer_token: "your-bearer-token"

# Health check configuration for services
health_checks:
  # Enable/disable health checks globally
  enabled: true

  # How often to perform health checks (in seconds)
  interval_secs: 30

  # Health check timeout (in seconds)
  timeout_secs: 5

  # Number of consecutive failures before marking as unhealthy
  failure_threshold: 3

  # Individual service health checks
  services:
    # N8n workflow automation
    - name: "n8n-0"
      endpoint: "http://100.81.76.55:30678/healthz"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 5
      response_time_threshold_ms: 1000

    # PostgreSQL database
    - name: "postgres-0"
      endpoint: "http://100.81.76.55:30543/health"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 5
      response_time_threshold_ms: 500

    # Redis cache
    - name: "redis-0"
      endpoint: "http://100.81.76.55:30379/health"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 3
      response_time_threshold_ms: 200

    # Prometheus metrics server
    - name: "prometheus-0"
      endpoint: "http://100.81.76.55:30090/-/healthy"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 5
      response_time_threshold_ms: 500

    # Grafana dashboard
    - name: "grafana-0"
      endpoint: "http://100.81.76.55:30300/api/health"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 5
      response_time_threshold_ms: 1000

    # Qdrant vector database
    - name: "qdrant-0"
      endpoint: "http://100.81.76.55:30633/health"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 10
      response_time_threshold_ms: 2000

    # Flowise AI workflow platform
    - name: "flowise-0"
      endpoint: "http://100.81.76.55:30850/api/v1/health"
      method: "GET"
      expected_status: [200]
      enabled: true
      timeout_secs: 10
      response_time_threshold_ms: 3000

    # Additional service example with custom headers
    # - name: "my-service"
    #   endpoint: "http://localhost:8080/health"
    #   method: "POST"
    #   expected_status: [200, 201]
    #   headers:
    #     Authorization: "Bearer your-token"
    #     Content-Type: "application/json"
    #   body: '{"ping": "health"}'
    #   enabled: true
    #   timeout_secs: 5
    #   response_time_threshold_ms: 500

# Node monitoring configuration
nodes:
  # Default values for all nodes
  defaults:
    # Default temperature unit: "C" or "F"
    temperature_unit: "C"

    # Default network unit: "MB/s", "GB/s", "KB/s"
    network_unit: "MB/s"

    # Whether to show GPU metrics by default
    show_gpu: false

  # Individual node configurations
  nodes:
    # Compute node (main workstation)
    - name: "pesubuntu"
      address: "100.72.98.106"
      labels:
        type: "compute"
        location: "homelab"
        role: "primary"
      overrides:
        display_name: "Compute Node"
        show_gpu: true

    # Service node (Kubernetes cluster)
    - name: "asuna"
      address: "100.81.76.55"
      labels:
        type: "service"
        location: "homelab"
        role: "kubernetes"
      overrides:
        display_name: "Service Node"
        show_gpu: false

# UI configuration
ui:
  # UI refresh rate (in milliseconds)
  refresh_rate_ms: 250

  # Display options
  show_graphs: true
  show_service_logs: true
  show_health_checks: true

  # Maximum number of log lines to display
  max_log_lines: 10

  # Layout configuration
  layout:
    # Main layout split: [nodes_percentage, services_percentage]
    main_split: [50, 50]

    # Service panel split: [graphs_percentage, health_percentage, logs_percentage]
    service_split: [40, 35, 25]

    # Node panel split: [specs_percentage, graphs_percentage]
    node_split: [50, 50]

  # Custom colors (optional - hex codes)
  # colors:
  #   primary: "#5e81ac"
  #   success: "#a3be8c"
  #   warning: "#ebcb8b"
  #   danger: "#bf616a"
  #   text: "#e5e9f0"
  #   border: "#4c566a"

# Logging configuration
logging:
  # Log level: "trace", "debug", "info", "warn", "error"
  level: "info"

  # Log to file
  log_to_file: false

  # Log file name (relative to config directory)
  log_file: "monitorium.log"

  # What to log
  log_health_checks: true
  log_prometheus_queries: false

  # Log rotation
  max_file_size_mb: 10
  max_files: 5

# =============================================================================
# Configuration Notes
# =============================================================================
#
# URLs and Addresses:
# - Update all URLs to match your actual service endpoints
# - Use internal IPs (100.x.x.x) for Tailscale connections
# - Use external IPs or domain names for external monitoring
#
# Health Checks:
# - Set appropriate timeout values for each service
# - Configure response time thresholds based on service SLAs
# - Use custom headers for services that require authentication
#
# Prometheus Queries:
# - Modify queries to match your Prometheus instance
# - Add labels to filter metrics more precisely
# - Adjust time windows based on your monitoring needs
#
# Layout:
# - Adjust split percentages to change panel sizes
# - Disable features you don't need to save space
# - Customize colors to match your preferences
#
# =============================================================================
#
# Setting up with an agent:
# 1. Copy this example to ~/.monitorium/config.yaml
# 2. Update all URLs and addresses to match your environment
# 3. Adjust health check endpoints and timeouts
# 4. Customize Prometheus queries if needed
# 5. Set layout and color preferences
# 6. Run: monitorium
#
# The application will automatically detect and load the configuration.
# =============================================================================